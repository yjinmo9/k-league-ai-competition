{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3db2d0b-9fb7-4e6a-a2ae-040006a4779d",
   "metadata": {},
   "source": [
    "## 1. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e82bf68-4f23-4a14-b69c-b34c351ffd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73493fd5-d0b6-4bb5-8ec2-148d5a920a81",
   "metadata": {},
   "source": [
    "## 2. 하이퍼파라미터 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2481df09-f3ac-4bf6-b307-cc24faf5e65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "BASE_PATH = \"open_track1/\"\n",
    "TRAIN_PATH = BASE_PATH + \"train.csv\"\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 5\n",
    "LR = 1e-3\n",
    "HIDDEN_DIM = 64\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a6953d-8cc2-424d-b9b1-d8b909c508fd",
   "metadata": {},
   "source": [
    "## 3. 데이터 로드 및 전처리\n",
    "### - 에피소드 별 (x,y) 시퀀스 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5767755-4f5c-400f-a5d9-ce0d28912a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15435/15435 [00:01<00:00, 12399.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "에피소드 수 :  15428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(BASE_PATH + \"train.csv\")\n",
    "df = df.sort_values([\"game_episode\", \"time_seconds\"]).reset_index(drop=True)\n",
    "\n",
    "episodes = []\n",
    "targets = []\n",
    "\n",
    "for _, g in tqdm(df.groupby(\"game_episode\")):\n",
    "    g = g.reset_index(drop=True)\n",
    "    if len(g) < 2:\n",
    "        continue\n",
    "\n",
    "    # 정규화된 좌표 준비\n",
    "    sx = g[\"start_x\"].values / 105.0\n",
    "    sy = g[\"start_y\"].values / 68.0\n",
    "    ex = g[\"end_x\"].values   / 105.0\n",
    "    ey = g[\"end_y\"].values   / 68.0\n",
    "\n",
    "    coords = []\n",
    "    for i in range(len(g)):\n",
    "        # 항상 start는 들어감\n",
    "        coords.append([sx[i], sy[i]])\n",
    "        # 마지막 행 이전까지만 end를 넣음 (마지막 end는 타깃이므로)\n",
    "        if i < len(g) - 1:\n",
    "            coords.append([ex[i], ey[i]])\n",
    "\n",
    "    seq = np.array(coords, dtype=\"float32\")        # [T, 2]\n",
    "    target = np.array([ex[-1], ey[-1]], dtype=\"float32\")  # 마지막 행 end_x, end_y\n",
    "\n",
    "    episodes.append(seq)\n",
    "    targets.append(target)\n",
    "\n",
    "print(\"에피소드 수 : \", len(episodes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66140869-2d3c-460d-8678-ae6d23d97b88",
   "metadata": {},
   "source": [
    "## 4. Custom Dataset / DataLoader 정의 및 Validation 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6b1b1d3-851b-4d29-8130-a14410345661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train episodes: 12342 valid episodes: 3086\n"
     ]
    }
   ],
   "source": [
    "class EpisodeDataset(Dataset):\n",
    "    def __init__(self, episodes, targets):\n",
    "        self.episodes = episodes\n",
    "        self.targets = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.episodes)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        seq = torch.tensor(self.episodes[idx])   # [T, 2]\n",
    "        tgt = torch.tensor(self.targets[idx])    # [2]\n",
    "        length = seq.size(0)\n",
    "        return seq, length, tgt\n",
    "\n",
    "def collate_fn(batch):\n",
    "    seqs, lengths, tgts = zip(*batch)\n",
    "    lengths = torch.tensor(lengths, dtype=torch.long)\n",
    "    padded = pad_sequence(seqs, batch_first=True)  # [B, T, 2]\n",
    "    tgts = torch.stack(tgts, dim=0)                # [B, 2]\n",
    "    return padded, lengths, tgts\n",
    "\n",
    "# 에피소드 단위 train / valid split\n",
    "idx_train, idx_valid = train_test_split(\n",
    "    np.arange(len(episodes)), test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "episodes_train = [episodes[i] for i in idx_train]\n",
    "targets_train  = [targets[i]  for i in idx_train]\n",
    "episodes_valid = [episodes[i] for i in idx_valid]\n",
    "targets_valid  = [targets[i]  for i in idx_valid]\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    EpisodeDataset(episodes_train, targets_train),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    ")\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    EpisodeDataset(episodes_valid, targets_valid),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    ")\n",
    "\n",
    "print(\"train episodes:\", len(episodes_train), \"valid episodes:\", len(episodes_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d4f89e-808e-41eb-bbc3-db4a32fab6a8",
   "metadata": {},
   "source": [
    "## 5. LSTM 베이스라인 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef323dcf-0a45-4323-ad8e-5bc8ed6c50f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMBaseline(nn.Module):\n",
    "    def __init__(self, input_dim=2, hidden_dim=64):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_dim,\n",
    "            hidden_size=hidden_dim,\n",
    "            num_layers=1,\n",
    "            batch_first=True,\n",
    "        )\n",
    "        self.fc = nn.Linear(hidden_dim, 2)  # (x_norm, y_norm)\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        # x: [B, T, 2], lengths: [B]\n",
    "        packed = pack_padded_sequence(\n",
    "            x, lengths.cpu(), batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        _, (h_n, _) = self.lstm(packed)\n",
    "        h_last = h_n[-1]      # [B, H] 마지막 layer의 hidden state\n",
    "        out = self.fc(h_last) # [B, 2]\n",
    "        return out\n",
    "\n",
    "model = LSTMBaseline(input_dim=2, hidden_dim=HIDDEN_DIM).to(DEVICE)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fca4d7-cd45-4140-bc42-deb004be7976",
   "metadata": {},
   "source": [
    "## 6. 모델 학습 및 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a302ea7-6c5b-4f39-b24d-e1403aa091db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 193/193 [00:24<00:00,  8.01it/s]\n",
      "100%|██████████| 49/49 [00:00<00:00, 113.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1] train_loss=0.0825 | valid_mean_dist=20.3420\n",
      " --> Best model updated! (dist=20.3420)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 193/193 [00:23<00:00,  8.15it/s]\n",
      "100%|██████████| 49/49 [00:00<00:00, 113.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2] train_loss=0.0375 | valid_mean_dist=18.5343\n",
      " --> Best model updated! (dist=18.5343)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 193/193 [00:23<00:00,  8.14it/s]\n",
      "100%|██████████| 49/49 [00:00<00:00, 111.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3] train_loss=0.0349 | valid_mean_dist=18.4319\n",
      " --> Best model updated! (dist=18.4319)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 193/193 [00:23<00:00,  8.17it/s]\n",
      "100%|██████████| 49/49 [00:00<00:00, 107.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 4] train_loss=0.0334 | valid_mean_dist=17.9715\n",
      " --> Best model updated! (dist=17.9715)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 193/193 [00:23<00:00,  8.16it/s]\n",
      "100%|██████████| 49/49 [00:00<00:00, 111.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 5] train_loss=0.0327 | valid_mean_dist=17.5932\n",
      " --> Best model updated! (dist=17.5932)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_dist = float(\"inf\")\n",
    "best_model_state = None\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    # --- Train ---\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "\n",
    "    for X, lengths, y in tqdm(train_loader):\n",
    "        X, lengths, y = X.to(DEVICE), lengths.to(DEVICE), y.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X, lengths)\n",
    "        loss = criterion(pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * X.size(0)\n",
    "\n",
    "    train_loss = total_loss / len(train_loader.dataset)\n",
    "\n",
    "    # --- Valid: 평균 유클리드 거리 ---\n",
    "    model.eval()\n",
    "    dists = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, lengths, y in tqdm(valid_loader):\n",
    "            X, lengths, y = X.to(DEVICE), lengths.to(DEVICE), y.to(DEVICE)\n",
    "            pred = model(X, lengths)\n",
    "\n",
    "            pred_np = pred.cpu().numpy()\n",
    "            true_np = y.cpu().numpy()\n",
    "\n",
    "            pred_x = pred_np[:, 0] * 105.0\n",
    "            pred_y = pred_np[:, 1] * 68.0\n",
    "            true_x = true_np[:, 0] * 105.0\n",
    "            true_y = true_np[:, 1] * 68.0\n",
    "\n",
    "            dist = np.sqrt((pred_x - true_x) ** 2 + (pred_y - true_y) ** 2)\n",
    "            dists.append(dist)\n",
    "\n",
    "    mean_dist = np.concatenate(dists).mean()  # 평균 유클리드 거리\n",
    "\n",
    "    print(\n",
    "        f\"[Epoch {epoch}] \"\n",
    "        f\"train_loss={train_loss:.4f} | \"\n",
    "        f\"valid_mean_dist={mean_dist:.4f}\"\n",
    "    )\n",
    "\n",
    "    # ----- BEST MODEL 업데이트 -----\n",
    "    if mean_dist < best_dist:\n",
    "        best_dist = mean_dist\n",
    "        best_model_state = model.state_dict().copy()\n",
    "        print(f\" --> Best model updated! (dist={best_dist:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2ddd96-c48d-432e-88ac-3872549e9857",
   "metadata": {},
   "source": [
    "## 7. 평가 데이터셋 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6849ef5-efac-4cfa-9ead-73b1f4dc1760",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2414 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2414/2414 [00:03<00:00, 774.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Best Model Load\n",
    "model.load_state_dict(best_model_state)\n",
    "model.eval()\n",
    "\n",
    "test_meta = pd.read_csv(BASE_PATH + \"test.csv\")\n",
    "submission = pd.read_csv(BASE_PATH + \"sample_submission.csv\")\n",
    "\n",
    "submission = submission.merge(test_meta, on=\"game_episode\", how=\"left\")\n",
    "\n",
    "preds_x, preds_y = [], []\n",
    "\n",
    "for _, row in tqdm(submission.iterrows(), total=len(submission)):\n",
    "    # path가 상대경로인 경우 BASE_PATH 추가\n",
    "    file_path = row[\"path\"] if row[\"path\"].startswith(\"open_track1/\") else BASE_PATH + row[\"path\"]\n",
    "    g = pd.read_csv(file_path).reset_index(drop=True)\n",
    "    # 정규화된 좌표 준비\n",
    "    sx = g[\"start_x\"].values / 105.0\n",
    "    sy = g[\"start_y\"].values / 68.0\n",
    "    ex = g[\"end_x\"].values / 105.0\n",
    "    ey = g[\"end_y\"].values / 68.0\n",
    "    \n",
    "    coords = []\n",
    "    for i in range(len(g)):\n",
    "        # start는 항상 존재하므로 그대로 사용\n",
    "        coords.append([sx[i], sy[i]])\n",
    "        # 마지막 행은 end_x가 NaN이므로 자동으로 제외됨\n",
    "        if i < len(g) - 1:\n",
    "            coords.append([ex[i], ey[i]])\n",
    "\n",
    "    seq = np.array(coords, dtype=\"float32\")  # [T, 2]\n",
    "\n",
    "    x = torch.tensor(seq).unsqueeze(0).to(DEVICE)      # [1, T, 2]\n",
    "    length = torch.tensor([seq.shape[0]]).to(DEVICE)   # [1]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred = model(x, length).cpu().numpy()[0]       # [2], 정규화 좌표\n",
    "\n",
    "    preds_x.append(pred[0] * 105.0)\n",
    "    preds_y.append(pred[1] * 68.0)\n",
    "print(\"Inference Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69009d4f-ed79-44e0-8ecf-8fd4e2cd0dd3",
   "metadata": {},
   "source": [
    "## 8. 제출 Submission 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14136f9d-5632-40c3-97ab-0d948dee0948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: baseline_submit.csv\n"
     ]
    }
   ],
   "source": [
    "submission[\"end_x\"] = preds_x\n",
    "submission[\"end_y\"] = preds_y\n",
    "submission[[\"game_episode\", \"end_x\", \"end_y\"]].to_csv(\"./baseline_submit.csv\", index=False)\n",
    "print(\"Saved: baseline_submit.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
