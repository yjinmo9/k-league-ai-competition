{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c6e05691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightgbm in /opt/miniconda3/lib/python3.13/site-packages (4.6.0)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/miniconda3/lib/python3.13/site-packages (from lightgbm) (2.1.3)\n",
      "Requirement already satisfied: scipy in /opt/miniconda3/lib/python3.13/site-packages (from lightgbm) (1.16.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b56c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ í•µì‹¬ í”¼ì²˜ 3ê°œ ì¶”ê°€ ì™„ë£Œ (dist_to_sideline, angle_to_goal_center, time_pos_inter)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8g/x3kqv_gx5hdb25l1fv6qd8jw0000gn/T/ipykernel_90174/1529377035.py:220: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  lastK = lastK.groupby(\"game_episode\", group_keys=False).apply(assign_pos_in_K)\n",
      "/var/folders/8g/x3kqv_gx5hdb25l1fv6qd8jw0000gn/T/ipykernel_90174/1529377035.py:291: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_train_feat = X_train_feat.fillna(0)\n",
      "/var/folders/8g/x3kqv_gx5hdb25l1fv6qd8jw0000gn/T/ipykernel_90174/1529377035.py:292: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_test_feat = X_test_feat.fillna(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ğŸ“Š ì—¬ëŸ¬ K ê°’ ë¹„êµ ì‹œì‘: [32, 35, 40, 45]\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "ğŸ”„ K=32 ì²˜ë¦¬ ì¤‘...\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8g/x3kqv_gx5hdb25l1fv6qd8jw0000gn/T/ipykernel_90174/1529377035.py:342: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  lastK = lastK.groupby(\"game_episode\", group_keys=False).apply(assign_pos_in_K)\n",
      "/var/folders/8g/x3kqv_gx5hdb25l1fv6qd8jw0000gn/T/ipykernel_90174/1529377035.py:379: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_train_feat = X_train_feat.fillna(0)\n",
      "/var/folders/8g/x3kqv_gx5hdb25l1fv6qd8jw0000gn/T/ipykernel_90174/1529377035.py:380: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_test_feat = X_test_feat.fillna(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Œ LGBM CV ì‹œì‘: n_splits=5, K=32\n",
      "[Fold 1] mean Euclidean = 14.667537\n",
      "[Fold 2] mean Euclidean = 14.796664\n",
      "[Fold 3] mean Euclidean = 14.588967\n",
      "[Fold 4] mean Euclidean = 14.262552\n",
      "[Fold 5] mean Euclidean = 14.656135\n",
      "âœ… K=32 CV ì™„ë£Œ | mean Euclidean = 14.594371 Â± 0.179011\n",
      "\n",
      "================================================================================\n",
      "ğŸ”„ K=35 ì²˜ë¦¬ ì¤‘...\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8g/x3kqv_gx5hdb25l1fv6qd8jw0000gn/T/ipykernel_90174/1529377035.py:342: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  lastK = lastK.groupby(\"game_episode\", group_keys=False).apply(assign_pos_in_K)\n",
      "/var/folders/8g/x3kqv_gx5hdb25l1fv6qd8jw0000gn/T/ipykernel_90174/1529377035.py:379: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_train_feat = X_train_feat.fillna(0)\n",
      "/var/folders/8g/x3kqv_gx5hdb25l1fv6qd8jw0000gn/T/ipykernel_90174/1529377035.py:380: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_test_feat = X_test_feat.fillna(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Œ LGBM CV ì‹œì‘: n_splits=5, K=35\n",
      "[Fold 1] mean Euclidean = 14.683465\n",
      "[Fold 2] mean Euclidean = 14.799056\n",
      "[Fold 3] mean Euclidean = 14.529432\n",
      "[Fold 4] mean Euclidean = 14.319081\n",
      "[Fold 5] mean Euclidean = 14.694736\n",
      "âœ… K=35 CV ì™„ë£Œ | mean Euclidean = 14.605154 Â± 0.166929\n",
      "\n",
      "================================================================================\n",
      "ğŸ”„ K=40 ì²˜ë¦¬ ì¤‘...\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8g/x3kqv_gx5hdb25l1fv6qd8jw0000gn/T/ipykernel_90174/1529377035.py:342: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  lastK = lastK.groupby(\"game_episode\", group_keys=False).apply(assign_pos_in_K)\n",
      "/var/folders/8g/x3kqv_gx5hdb25l1fv6qd8jw0000gn/T/ipykernel_90174/1529377035.py:379: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_train_feat = X_train_feat.fillna(0)\n",
      "/var/folders/8g/x3kqv_gx5hdb25l1fv6qd8jw0000gn/T/ipykernel_90174/1529377035.py:380: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  X_test_feat = X_test_feat.fillna(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Œ LGBM CV ì‹œì‘: n_splits=5, K=40\n",
      "[Fold 1] mean Euclidean = 14.751481\n",
      "[Fold 2] mean Euclidean = 14.781937\n",
      "[Fold 3] mean Euclidean = 14.658883\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 409\u001b[39m\n\u001b[32m    407\u001b[39m \u001b[38;5;66;03m# X ëª¨ë¸\u001b[39;00m\n\u001b[32m    408\u001b[39m model_x = LGBMRegressor(**LGB_PARAMS)\n\u001b[32m--> \u001b[39m\u001b[32m409\u001b[39m \u001b[43mmodel_x\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_tr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_tr_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_va\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_va_x\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrmse\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[38;5;66;03m# Y ëª¨ë¸\u001b[39;00m\n\u001b[32m    416\u001b[39m model_y = LGBMRegressor(**LGB_PARAMS)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/lightgbm/sklearn.py:1398\u001b[39m, in \u001b[36mLGBMRegressor.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[39m\n\u001b[32m   1381\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[32m   1382\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1383\u001b[39m     X: _LGBM_ScikitMatrixLike,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1395\u001b[39m     init_model: Optional[Union[\u001b[38;5;28mstr\u001b[39m, Path, Booster, LGBMModel]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1396\u001b[39m ) -> \u001b[33m\"\u001b[39m\u001b[33mLGBMRegressor\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1397\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1398\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1399\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1400\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1401\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1402\u001b[39m \u001b[43m        \u001b[49m\u001b[43minit_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1403\u001b[39m \u001b[43m        \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1404\u001b[39m \u001b[43m        \u001b[49m\u001b[43meval_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1405\u001b[39m \u001b[43m        \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1406\u001b[39m \u001b[43m        \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1407\u001b[39m \u001b[43m        \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1408\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1409\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1410\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1411\u001b[39m \u001b[43m        \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1412\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1413\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/lightgbm/sklearn.py:1049\u001b[39m, in \u001b[36mLGBMModel.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[39m\n\u001b[32m   1046\u001b[39m evals_result: _EvalResultDict = {}\n\u001b[32m   1047\u001b[39m callbacks.append(record_evaluation(evals_result))\n\u001b[32m-> \u001b[39m\u001b[32m1049\u001b[39m \u001b[38;5;28mself\u001b[39m._Booster = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1050\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1051\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1052\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1054\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1055\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1056\u001b[39m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1057\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1058\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1060\u001b[39m \u001b[38;5;66;03m# This populates the property self.n_features_, the number of features in the fitted model,\u001b[39;00m\n\u001b[32m   1061\u001b[39m \u001b[38;5;66;03m# and so should only be set after fitting.\u001b[39;00m\n\u001b[32m   1062\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m   1063\u001b[39m \u001b[38;5;66;03m# The related property self._n_features_in, which populates self.n_features_in_,\u001b[39;00m\n\u001b[32m   1064\u001b[39m \u001b[38;5;66;03m# is set BEFORE fitting.\u001b[39;00m\n\u001b[32m   1065\u001b[39m \u001b[38;5;28mself\u001b[39m._n_features = \u001b[38;5;28mself\u001b[39m._Booster.num_feature()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/lightgbm/engine.py:322\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, keep_training_booster, callbacks)\u001b[39m\n\u001b[32m    310\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m cb \u001b[38;5;129;01min\u001b[39;00m callbacks_before_iter:\n\u001b[32m    311\u001b[39m     cb(\n\u001b[32m    312\u001b[39m         callback.CallbackEnv(\n\u001b[32m    313\u001b[39m             model=booster,\n\u001b[32m   (...)\u001b[39m\u001b[32m    319\u001b[39m         )\n\u001b[32m    320\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m322\u001b[39m \u001b[43mbooster\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    324\u001b[39m evaluation_result_list: List[_LGBM_BoosterEvalMethodResultType] = []\n\u001b[32m    325\u001b[39m \u001b[38;5;66;03m# check evaluation result.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/miniconda3/lib/python3.13/site-packages/lightgbm/basic.py:4155\u001b[39m, in \u001b[36mBooster.update\u001b[39m\u001b[34m(self, train_set, fobj)\u001b[39m\n\u001b[32m   4152\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__set_objective_to_none:\n\u001b[32m   4153\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[33m\"\u001b[39m\u001b[33mCannot update due to null objective function.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   4154\u001b[39m _safe_call(\n\u001b[32m-> \u001b[39m\u001b[32m4155\u001b[39m     \u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLGBM_BoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4156\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4157\u001b[39m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mis_finished\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4158\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4159\u001b[39m )\n\u001b[32m   4160\u001b[39m \u001b[38;5;28mself\u001b[39m.__is_predicted_cur_iter = [\u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.__num_dataset)]\n\u001b[32m   4161\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m is_finished.value == \u001b[32m1\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "# ============================================================\n",
    "# K-League Track1 - LGBM Direct Regression (Wide Feature + CV)\n",
    "# ------------------------------------------------------------\n",
    "# âœ… ëª©í‘œ: end_x, end_yë¥¼ BIN ì—†ì´ \"ì§ì ‘ íšŒê·€\"ë¡œ ì˜ˆì¸¡\n",
    "# âœ… í•µì‹¬: ë§ˆì§€ë§‰ K ì´ë²¤íŠ¸ë¥¼ wide featureë¡œ í¼ì¹œ ë’¤,\n",
    "#         LGBMRegressorë¡œ target_x, target_y ê°ê° í•™ìŠµ\n",
    "# âœ… ì˜µì…˜: KFoldë¡œ CV(OOF) ì ìˆ˜ í™•ì¸ í›„, ì „ì²´ í•™ìŠµ â†’ Test ì˜ˆì¸¡\n",
    "#\n",
    "# âš ï¸ BASE_PATH ë° íŒŒì¼ ê²½ë¡œëŠ” ë°˜ë“œì‹œ ê·¸ëŒ€ë¡œ ìœ ì§€\n",
    "# ============================================================\n",
    "\n",
    "# ----------------------\n",
    "# 0. ì„¤ì • (ê²½ë¡œ/í•˜ì´í¼íŒŒë¼ë¯¸í„°)\n",
    "# ----------------------\n",
    "BASE_PATH = \"open_track1/\"\n",
    "PATH_TRAIN = os.path.join(BASE_PATH, \"train.csv\")\n",
    "PATH_TEST = os.path.join(BASE_PATH, \"test.csv\")\n",
    "PATH_MATCH_INFO = os.path.join(BASE_PATH, \"match_info.csv\")\n",
    "PATH_SAMPLE_SUB = os.path.join(BASE_PATH, \"sample_submission.csv\")\n",
    "\n",
    "# ì—¬ëŸ¬ K ê°’ ë¹„êµ (30 ì´ìƒ)\n",
    "K_LIST = [32, 35, 40, 45]  # ë¹„êµí•  K ê°’ë“¤\n",
    "K_BEST = None  # ìµœê³  ì„±ëŠ¥ K ê°’ (ìë™ ì„¤ì •ë¨)\n",
    "\n",
    "# CV ì„¤ì •\n",
    "USE_CV = True\n",
    "N_SPLITS = 5\n",
    "SEED = 42\n",
    "\n",
    "# LGBM ê¸°ë³¸ íŒŒë¼ë¯¸í„° (ë„ˆë¬´ ê³¼íŠœë‹í•˜ì§€ ë§ê³ , ì•ˆì •ì ìœ¼ë¡œ ì‹œì‘)\n",
    "LGB_PARAMS = dict(\n",
    "    n_estimators=5000,          # early stoppingìœ¼ë¡œ ì‹¤ì œ ì‚¬ìš© ê°œìˆ˜ ìë™ ê²°ì •\n",
    "    learning_rate=0.03,\n",
    "    num_leaves=64,\n",
    "    max_depth=-1,\n",
    "    min_child_samples=50,       # (=min_data_in_leaf ë¹„ìŠ·)\n",
    "    subsample=0.8,              # bagging_fraction\n",
    "    subsample_freq=1,           # bagging_freq\n",
    "    colsample_bytree=0.8,       # feature_fraction\n",
    "    reg_alpha=0.0,\n",
    "    reg_lambda=0.0,\n",
    "    random_state=SEED,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# ----------------------\n",
    "# 1. ë°ì´í„° ë¡œë“œ\n",
    "# ----------------------\n",
    "train = pd.read_csv(PATH_TRAIN)\n",
    "test_index = pd.read_csv(PATH_TEST)\n",
    "match_info = pd.read_csv(PATH_MATCH_INFO)  # í˜„ì¬ ì½”ë“œì—ì„œëŠ” ì§ì ‘ ì‚¬ìš© ì•ˆ í•¨ (ì›ë³¸ ìœ ì§€)\n",
    "sample_sub = pd.read_csv(PATH_SAMPLE_SUB)\n",
    "\n",
    "# testëŠ” episodeë³„ csvë¡œ ë”°ë¡œ ì¡´ì¬ â†’ í•©ì³ì„œ eventsë¡œ ë§Œë“¤ê¸°\n",
    "test_events_list = []\n",
    "for _, row in test_index.iterrows():\n",
    "    test_path = os.path.join(BASE_PATH, row[\"path\"].lstrip(\"./\"))\n",
    "    df_ep = pd.read_csv(test_path)\n",
    "    test_events_list.append(df_ep)\n",
    "\n",
    "test_events = pd.concat(test_events_list, ignore_index=True)\n",
    "\n",
    "train[\"is_train\"] = 1\n",
    "test_events[\"is_train\"] = 0\n",
    "\n",
    "events = pd.concat([train, test_events], ignore_index=True)\n",
    "\n",
    "# ----------------------\n",
    "# 2. ê¸°ë³¸ ì •ë ¬ + episode ë‚´ ì¸ë±ìŠ¤\n",
    "# ----------------------\n",
    "events = events.sort_values([\"game_episode\", \"time_seconds\", \"action_id\"]).reset_index(drop=True)\n",
    "\n",
    "events[\"event_idx\"] = events.groupby(\"game_episode\").cumcount()\n",
    "events[\"n_events\"] = events.groupby(\"game_episode\")[\"event_idx\"].transform(\"max\") + 1\n",
    "events[\"ep_idx_norm\"] = events[\"event_idx\"] / (events[\"n_events\"] - 1).clip(lower=1)\n",
    "\n",
    "# ----------------------\n",
    "# 3. ì‹œê°„/ê³µê°„ feature\n",
    "# ----------------------\n",
    "events[\"prev_time\"] = events.groupby(\"game_episode\")[\"time_seconds\"].shift(1)\n",
    "events[\"dt\"] = (events[\"time_seconds\"] - events[\"prev_time\"]).fillna(0.0)\n",
    "\n",
    "events[\"dx\"] = events[\"end_x\"] - events[\"start_x\"]\n",
    "events[\"dy\"] = events[\"end_y\"] - events[\"start_y\"]\n",
    "events[\"dist\"] = np.sqrt(events[\"dx\"]**2 + events[\"dy\"]**2)\n",
    "\n",
    "# dt=0 ë³´í˜¸\n",
    "events[\"speed\"] = events[\"dist\"] / events[\"dt\"].replace(0, 1e-3)\n",
    "\n",
    "# zone / lane\n",
    "events[\"x_zone\"] = (events[\"start_x\"] / (105/7)).astype(int).clip(0, 6)\n",
    "events[\"lane\"] = pd.cut(\n",
    "    events[\"start_y\"],\n",
    "    bins=[0, 68/3, 2*68/3, 68],\n",
    "    labels=[0, 1, 2],\n",
    "    include_lowest=True\n",
    ").astype(int)\n",
    "\n",
    "# ----------------------\n",
    "# 3-1. ì½”ë„ˆ ê´€ë ¨ í”¼ì²˜ (Corner Features)\n",
    "# ----------------------\n",
    "events[\"angle_to_goal\"] = np.arctan2(\n",
    "    34 - events[\"start_y\"],\n",
    "    105 - events[\"start_x\"]\n",
    ") * 180 / np.pi\n",
    "\n",
    "events[\"dist_corner_top\"] = np.sqrt((105 - events[\"start_x\"])**2 + (0 - events[\"start_y\"])**2)\n",
    "events[\"dist_corner_bottom\"] = np.sqrt((105 - events[\"start_x\"])**2 + (68 - events[\"start_y\"])**2)\n",
    "events[\"dist_to_nearest_corner\"] = events[[\"dist_corner_top\", \"dist_corner_bottom\"]].min(axis=1)\n",
    "\n",
    "events[\"is_corner_area\"] = ((events[\"start_x\"] > 100) &\n",
    "                            ((events[\"start_y\"] < 5) | (events[\"start_y\"] > 63))).astype(int)\n",
    "\n",
    "events[\"angle_goal_x_corner\"] = events[\"angle_to_goal\"] * events[\"is_corner_area\"]\n",
    "events[\"dist_corner_x_angle\"] = events[\"dist_to_nearest_corner\"] * events[\"angle_to_goal\"]\n",
    "\n",
    "# ----------------------\n",
    "# 3-2. ìƒˆë¡œìš´ í•µì‹¬ í”¼ì²˜ 3ê°œ (ê³ ë“ì ìš©)\n",
    "# ----------------------\n",
    "events[\"dist_to_sideline\"] = events[\"start_y\"].apply(lambda y: min(y, 68-y))\n",
    "\n",
    "# ë¼ë””ì•ˆ ë‹¨ìœ„\n",
    "events[\"angle_to_goal_center\"] = np.arctan2(\n",
    "    34 - events[\"start_y\"],\n",
    "    105 - events[\"start_x\"]\n",
    ")\n",
    "\n",
    "events[\"time_pos_inter\"] = events[\"ep_idx_norm\"] * events[\"start_x\"]\n",
    "\n",
    "print(\"âœ“ í•µì‹¬ í”¼ì²˜ 3ê°œ ì¶”ê°€ ì™„ë£Œ (dist_to_sideline, angle_to_goal_center, time_pos_inter)\")\n",
    "\n",
    "# ----------------------\n",
    "# 4. ë¼ë²¨ ë° episode-level ë©”íƒ€ (train ì „ìš©)\n",
    "# ----------------------\n",
    "train_events = events[events[\"is_train\"] == 1].copy()\n",
    "\n",
    "last_events = (\n",
    "    train_events\n",
    "    .groupby(\"game_episode\", as_index=False)\n",
    "    .tail(1)\n",
    "    .copy()\n",
    ")\n",
    "\n",
    "labels = last_events[[\"game_episode\", \"end_x\", \"end_y\"]].rename(\n",
    "    columns={\"end_x\": \"target_x\", \"end_y\": \"target_y\"}\n",
    ")\n",
    "\n",
    "ep_meta = last_events[[\"game_episode\", \"game_id\", \"team_id\", \"is_home\", \"period_id\", \"time_seconds\"]].copy()\n",
    "ep_meta = ep_meta.rename(columns={\"team_id\": \"final_team_id\"})\n",
    "\n",
    "ep_meta[\"game_clock_min\"] = np.where(\n",
    "    ep_meta[\"period_id\"] == 1,\n",
    "    ep_meta[\"time_seconds\"] / 60.0,\n",
    "    45.0 + ep_meta[\"time_seconds\"] / 60.0\n",
    ")\n",
    "\n",
    "# ----------------------\n",
    "# 5. ê³µê²© íŒ€ í”Œë˜ê·¸ (final_team vs ìƒëŒ€)\n",
    "# ----------------------\n",
    "events = events.merge(\n",
    "    ep_meta[[\"game_episode\", \"final_team_id\"]],\n",
    "    on=\"game_episode\",\n",
    "    how=\"left\"\n",
    ")\n",
    "events[\"is_final_team\"] = (events[\"team_id\"] == events[\"final_team_id\"]).astype(int)\n",
    "\n",
    "# ----------------------\n",
    "# 6. ì…ë ¥ìš© eventsì—ì„œ ë§ˆì§€ë§‰ ì´ë²¤íŠ¸ íƒ€ê¹ƒ ì •ë³´ ê°€ë¦¬ê¸°\n",
    "# ----------------------\n",
    "events[\"last_idx\"] = events.groupby(\"game_episode\")[\"event_idx\"].transform(\"max\")\n",
    "events[\"is_last\"] = (events[\"event_idx\"] == events[\"last_idx\"]).astype(int)\n",
    "\n",
    "mask_last = events[\"is_last\"] == 1\n",
    "for col in [\"end_x\", \"end_y\", \"dx\", \"dy\", \"dist\", \"speed\"]:\n",
    "    events.loc[mask_last, col] = np.nan\n",
    "\n",
    "# ----------------------\n",
    "# 7. ì¹´í…Œê³ ë¦¬ ì¸ì½”ë”© (type_name, result_name, team_id ë“±)\n",
    "# ----------------------\n",
    "events[\"type_name\"] = events[\"type_name\"].fillna(\"__NA_TYPE__\")\n",
    "events[\"result_name\"] = events[\"result_name\"].fillna(\"__NA_RES__\")\n",
    "\n",
    "le_type = LabelEncoder()\n",
    "le_res = LabelEncoder()\n",
    "\n",
    "events[\"type_id\"] = le_type.fit_transform(events[\"type_name\"])\n",
    "events[\"res_id\"] = le_res.fit_transform(events[\"result_name\"])\n",
    "\n",
    "if events[\"team_id\"].dtype == \"object\":\n",
    "    le_team = LabelEncoder()\n",
    "    events[\"team_id_enc\"] = le_team.fit_transform(events[\"team_id\"])\n",
    "else:\n",
    "    events[\"team_id_enc\"] = events[\"team_id\"].astype(int)\n",
    "\n",
    "# ----------------------\n",
    "# 8. ë§ˆì§€ë§‰ K ì´ë²¤íŠ¸ë§Œ ì‚¬ìš© (lastK)\n",
    "# ----------------------\n",
    "events[\"rev_idx\"] = events.groupby(\"game_episode\")[\"event_idx\"].transform(\n",
    "    lambda s: s.max() - s\n",
    ")\n",
    "lastK = events[events[\"rev_idx\"] < K].copy()\n",
    "\n",
    "def assign_pos_in_K(df):\n",
    "    df = df.sort_values(\"event_idx\")  # ì˜¤ë˜ëœ â†’ ìµœê·¼\n",
    "    L = len(df)\n",
    "    df = df.copy()\n",
    "    df[\"pos_in_K\"] = np.arange(K - L, K)\n",
    "    return df\n",
    "\n",
    "lastK = lastK.groupby(\"game_episode\", group_keys=False).apply(assign_pos_in_K)\n",
    "\n",
    "# ----------------------\n",
    "# 9. wide feature pivot\n",
    "# ----------------------\n",
    "num_cols = [\n",
    "    \"start_x\", \"start_y\",\n",
    "    \"end_x\", \"end_y\",\n",
    "    \"dx\", \"dy\", \"dist\", \"speed\",\n",
    "    \"dt\",\n",
    "    \"ep_idx_norm\",\n",
    "    \"x_zone\", \"lane\",\n",
    "    \"is_final_team\",\n",
    "    # ì½”ë„ˆ ê´€ë ¨\n",
    "    \"angle_to_goal\",\n",
    "    \"dist_to_nearest_corner\",\n",
    "    \"is_corner_area\",\n",
    "    \"angle_goal_x_corner\",\n",
    "    \"dist_corner_x_angle\",\n",
    "    # í•µì‹¬ 3ê°œ\n",
    "    \"dist_to_sideline\",\n",
    "    \"angle_to_goal_center\",\n",
    "    \"time_pos_inter\",\n",
    "]\n",
    "\n",
    "cat_cols = [\n",
    "    \"type_id\",\n",
    "    \"res_id\",\n",
    "    \"team_id_enc\",\n",
    "    \"is_home\",\n",
    "    \"period_id\",\n",
    "    \"is_last\",\n",
    "]\n",
    "\n",
    "feature_cols = num_cols + cat_cols\n",
    "wide = lastK[[\"game_episode\", \"pos_in_K\"] + feature_cols].copy()\n",
    "\n",
    "wide_num = wide.pivot_table(index=\"game_episode\", columns=\"pos_in_K\", values=num_cols, aggfunc=\"first\")\n",
    "wide_cat = wide.pivot_table(index=\"game_episode\", columns=\"pos_in_K\", values=cat_cols, aggfunc=\"first\")\n",
    "\n",
    "wide_num.columns = [f\"{c}_{int(pos)}\" for (c, pos) in wide_num.columns]\n",
    "wide_cat.columns = [f\"{c}_{int(pos)}\" for (c, pos) in wide_cat.columns]\n",
    "\n",
    "X = pd.concat([wide_num, wide_cat], axis=1).reset_index()\n",
    "\n",
    "# episode-level ë©”íƒ€ ë¶™ì´ê¸°\n",
    "X = X.merge(\n",
    "    ep_meta[[\"game_episode\", \"game_id\", \"game_clock_min\", \"final_team_id\", \"is_home\", \"period_id\"]],\n",
    "    on=\"game_episode\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# train ë¼ë²¨ ë¶™ì´ê¸°\n",
    "X = X.merge(labels, on=\"game_episode\", how=\"left\")\n",
    "\n",
    "# ----------------------\n",
    "# 10. train/test ë¶„ë¦¬\n",
    "# ----------------------\n",
    "train_mask = X[\"game_episode\"].isin(labels[\"game_episode\"])\n",
    "X_train = X[train_mask].copy()\n",
    "X_test = X[~train_mask].copy()\n",
    "\n",
    "y_train_x = X_train[\"target_x\"].astype(float).values\n",
    "y_train_y = X_train[\"target_y\"].astype(float).values\n",
    "\n",
    "drop_cols = [\"game_episode\", \"game_id\", \"target_x\", \"target_y\"]\n",
    "\n",
    "X_train_feat = X_train.drop(columns=drop_cols)\n",
    "X_test_feat = X_test.drop(columns=[c for c in drop_cols if c in X_test.columns])\n",
    "\n",
    "# ê²°ì¸¡ ì²˜ë¦¬\n",
    "X_train_feat = X_train_feat.fillna(0)\n",
    "X_test_feat = X_test_feat.fillna(0)\n",
    "\n",
    "# is_home ì»¬ëŸ¼ì„ ìˆ«ìë¡œ ë³€í™˜ (LightGBM í˜¸í™˜ì„±)\n",
    "for col in X_train_feat.columns:\n",
    "    if \"is_home\" in col and X_train_feat[col].dtype == \"object\":\n",
    "        X_train_feat[col] = pd.to_numeric(X_train_feat[col], errors=\"coerce\").fillna(0).astype(int)\n",
    "        if col in X_test_feat.columns:\n",
    "            X_test_feat[col] = pd.to_numeric(X_test_feat[col], errors=\"coerce\").fillna(0).astype(int)\n",
    "    \n",
    "    # period_id ì»¬ëŸ¼ë„ í™•ì¸\n",
    "    if \"period_id\" in col and X_train_feat[col].dtype == \"object\":\n",
    "        X_train_feat[col] = pd.to_numeric(X_train_feat[col], errors=\"coerce\").fillna(1).astype(int)\n",
    "        if col in X_test_feat.columns:\n",
    "            X_test_feat[col] = pd.to_numeric(X_test_feat[col], errors=\"coerce\").fillna(1).astype(int)\n",
    "\n",
    "# ----------------------\n",
    "# 8. Wide feature ìƒì„±\n",
    "# ----------------------\n",
    "events[\"rev_idx\"] = events.groupby(\"game_episode\")[\"event_idx\"].transform(\n",
    "    lambda s: s.max() - s\n",
    ")\n",
    "lastK = events[events[\"rev_idx\"] < K].copy()\n",
    "\n",
    "def assign_pos_in_K(df):\n",
    "    df = df.sort_values(\"event_idx\")\n",
    "    L = len(df)\n",
    "    df = df.copy()\n",
    "    df[\"pos_in_K\"] = np.arange(K - L, K)\n",
    "    return df\n",
    "\n",
    "lastK = lastK.groupby(\"game_episode\", group_keys=False).apply(assign_pos_in_K)\n",
    "\n",
    "feature_cols = num_cols + cat_cols\n",
    "wide = lastK[[\"game_episode\", \"pos_in_K\"] + feature_cols].copy()\n",
    "\n",
    "wide_num = wide.pivot_table(index=\"game_episode\", columns=\"pos_in_K\", values=num_cols, aggfunc=\"first\")\n",
    "wide_cat = wide.pivot_table(index=\"game_episode\", columns=\"pos_in_K\", values=cat_cols, aggfunc=\"first\")\n",
    "\n",
    "wide_num.columns = [f\"{c}_{int(pos)}\" for (c, pos) in wide_num.columns]\n",
    "wide_cat.columns = [f\"{c}_{int(pos)}\" for (c, pos) in wide_cat.columns]\n",
    "\n",
    "X = pd.concat([wide_num, wide_cat], axis=1).reset_index()\n",
    "\n",
    "# episode-level ë©”íƒ€ ë¶™ì´ê¸°\n",
    "X = X.merge(\n",
    "    ep_meta[[\"game_episode\", \"game_id\", \"game_clock_min\", \"final_team_id\", \"is_home\", \"period_id\"]],\n",
    "    on=\"game_episode\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "# train ë¼ë²¨ ë¶™ì´ê¸°\n",
    "X = X.merge(labels, on=\"game_episode\", how=\"left\")\n",
    "\n",
    "# ----------------------\n",
    "# 9. train/test ë¶„ë¦¬\n",
    "# ----------------------\n",
    "train_mask = X[\"game_episode\"].isin(labels[\"game_episode\"])\n",
    "X_train = X[train_mask].copy()\n",
    "X_test = X[~train_mask].copy()\n",
    "\n",
    "y_train_x = X_train[\"target_x\"].astype(float).values\n",
    "y_train_y = X_train[\"target_y\"].astype(float).values\n",
    "\n",
    "drop_cols = [\"game_episode\", \"game_id\", \"target_x\", \"target_y\"]\n",
    "\n",
    "X_train_feat = X_train.drop(columns=drop_cols)\n",
    "X_test_feat = X_test.drop(columns=[c for c in drop_cols if c in X_test.columns])\n",
    "\n",
    "# ê²°ì¸¡ ì²˜ë¦¬\n",
    "X_train_feat = X_train_feat.fillna(0)\n",
    "X_test_feat = X_test_feat.fillna(0)\n",
    "\n",
    "# is_home ì»¬ëŸ¼ì„ ìˆ«ìë¡œ ë³€í™˜ (LightGBM í˜¸í™˜ì„±)\n",
    "for col in X_train_feat.columns:\n",
    "    if \"is_home\" in col and X_train_feat[col].dtype == \"object\":\n",
    "        X_train_feat[col] = pd.to_numeric(X_train_feat[col], errors=\"coerce\").fillna(0).astype(int)\n",
    "        if col in X_test_feat.columns:\n",
    "            X_test_feat[col] = pd.to_numeric(X_test_feat[col], errors=\"coerce\").fillna(0).astype(int)\n",
    "    \n",
    "    # period_id ì»¬ëŸ¼ë„ í™•ì¸\n",
    "    if \"period_id\" in col and X_train_feat[col].dtype == \"object\":\n",
    "        X_train_feat[col] = pd.to_numeric(X_train_feat[col], errors=\"coerce\").fillna(1).astype(int)\n",
    "        if col in X_test_feat.columns:\n",
    "            X_test_feat[col] = pd.to_numeric(X_test_feat[col], errors=\"coerce\").fillna(1).astype(int)\n",
    "\n",
    "# ----------------------\n",
    "# 10. CVë¡œ OOF ì ìˆ˜ í™•ì¸\n",
    "# ----------------------\n",
    "def euclidean_mean(y_true_x, y_true_y, y_pred_x, y_pred_y):\n",
    "    dx = y_true_x - y_pred_x\n",
    "    dy = y_true_y - y_pred_y\n",
    "    return np.mean(np.sqrt(dx*dx + dy*dy))\n",
    "\n",
    "if USE_CV:\n",
    "    kf = KFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "    fold_scores = []\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(f\"ğŸ“Œ LGBM CV ì‹œì‘: n_splits={N_SPLITS}, K={K}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for fold, (tr_idx, va_idx) in enumerate(kf.split(X_train_feat), 1):\n",
    "        X_tr, X_va = X_train_feat.iloc[tr_idx], X_train_feat.iloc[va_idx]\n",
    "        y_tr_x, y_va_x = y_train_x[tr_idx], y_train_x[va_idx]\n",
    "        y_tr_y, y_va_y = y_train_y[tr_idx], y_train_y[va_idx]\n",
    "        \n",
    "        # X ëª¨ë¸\n",
    "        model_x = LGBMRegressor(**LGB_PARAMS)\n",
    "        model_x.fit(\n",
    "            X_tr, y_tr_x,\n",
    "            eval_set=[(X_va, y_va_x)],\n",
    "            eval_metric=\"rmse\",\n",
    "        )\n",
    "        \n",
    "        # Y ëª¨ë¸\n",
    "        model_y = LGBMRegressor(**LGB_PARAMS)\n",
    "        model_y.fit(\n",
    "            X_tr, y_tr_y,\n",
    "            eval_set=[(X_va, y_va_y)],\n",
    "            eval_metric=\"rmse\",\n",
    "        )\n",
    "        \n",
    "        pred_va_x = model_x.predict(X_va)\n",
    "        pred_va_y = model_y.predict(X_va)\n",
    "        \n",
    "        # í•„ë“œ ë²”ìœ„ë¡œ í´ë¦½\n",
    "        pred_va_x = np.clip(pred_va_x, 0, 105)\n",
    "        pred_va_y = np.clip(pred_va_y, 0, 68)\n",
    "        \n",
    "        fold_euc = euclidean_mean(y_va_x, y_va_y, pred_va_x, pred_va_y)\n",
    "        fold_scores.append(fold_euc)\n",
    "        \n",
    "        print(f\"[Fold {fold}] mean Euclidean = {fold_euc:.6f}\")\n",
    "    \n",
    "    cv_mean = float(np.mean(fold_scores))\n",
    "    cv_std = float(np.std(fold_scores))\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(f\"âœ… CV ì™„ë£Œ | mean Euclidean = {cv_mean:.6f} Â± {cv_std:.6f}\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "# ----------------------\n",
    "# 12. ìµœì¢… í•™ìŠµ(ì „ì²´ train) + test ì˜ˆì¸¡\n",
    "# ----------------------\n",
    "print(\"=\" * 80)\n",
    "print(\"ğŸ“Œ ì „ì²´ Trainìœ¼ë¡œ ìµœì¢… ëª¨ë¸ í•™ìŠµ í›„ Test ì˜ˆì¸¡ ì‹œì‘...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "final_model_x = LGBMRegressor(**LGB_PARAMS)\n",
    "final_model_x.fit(X_train_feat, y_train_x)\n",
    "\n",
    "final_model_y = LGBMRegressor(**LGB_PARAMS)\n",
    "final_model_y.fit(X_train_feat, y_train_y)\n",
    "\n",
    "pred_x = final_model_x.predict(X_test_feat)\n",
    "pred_y = final_model_y.predict(X_test_feat)\n",
    "\n",
    "pred_x = np.clip(pred_x, 0, 105)\n",
    "pred_y = np.clip(pred_y, 0, 68)\n",
    "\n",
    "# ----------------------\n",
    "# 13. submission ìƒì„± (ì›ë³¸ ë°©ì‹ ìœ ì§€)\n",
    "# ----------------------\n",
    "sub = sample_sub.copy()\n",
    "\n",
    "pred_df = X_test[[\"game_episode\"]].copy()\n",
    "pred_df[\"end_x\"] = pred_x\n",
    "pred_df[\"end_y\"] = pred_y\n",
    "\n",
    "sub = sub.drop(columns=[\"end_x\", \"end_y\"], errors=\"ignore\")\n",
    "sub = sub.merge(pred_df, on=\"game_episode\", how=\"left\")\n",
    "\n",
    "submission_filename = f\"submission_lgbm_direct_k{K}.csv\"\n",
    "sub.to_csv(submission_filename, index=False)\n",
    "\n",
    "print(f\"âœ… Saved: {submission_filename}\")\n",
    "print(\"ğŸ‰ ì™„ë£Œ!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
